# WO-07 — Γ builder (seams as linear equalities)

## Purpose

From Π-normalized trains + detected invariants, assemble **interface constraints** as a sparse linear system
[
A,\mathrm{vec}(X)=b,\quad b=\mathbf 0,
]
where each row encodes an **equality of two pixels (same color distribution)**, e.g. (X[i,j,:]=X[i,j',:]). These constraints will be fed to the convex path (CVXPY) and checked during cloth descent.

ARC grids are small rectangular integer matrices (0–9), JSON `train`/`test` (see anchors).

---

## Anchors to read

* `docs/anchors/00-vision-universe.md` — GLUE = lawful composition; Π/FREE.
* `docs/anchors/01-arc-on-the-cloth.md` — Γ = linear equalities; Z = product of simplexes.
* `docs/anchors/03-invariants-catalog-v1.md` — §§2–5 (periods, mirror, concat, block).
* `docs/anchors/04-receipts-checklist.md` — Γ receipts (rank, equality residuals).

---

## Reused, mature libraries (no custom math)

* **SciPy sparse** to **build A** efficiently:

  * `scipy.sparse.coo_matrix` for triplet construction; convert to CSR for solves. Docs emphasize COO→CSR for fast ops and auto-summing duplicates. ([SciPy Documentation][1])
  * `scipy.sparse.csr_matrix` for the final matrix handed to solvers. ([SciPy Documentation][2])
  * `scipy.sparse.kron` for block structure when needed (e.g., tying all C color channels at once). ([SciPy Documentation][3])
  * Sparse overview (types, when to use). ([SciPy Documentation][4])
* **NumPy** to **index/flatten**:

  * `numpy.ravel_multi_index` to map (i,j,c) → flat index of vec(X) with row-major order. ([NumPy][5])
  * `numpy.ravel` / `reshape(-1, order='C')` semantics for consistent flattening. ([NumPy][6])
  * Basic/advanced indexing rules to avoid hidden copies. ([NumPy][7])
* **Rank (receipt)**:

  * For small A: `numpy.linalg.matrix_rank` (SVD-based). ([NumPy][8])
  * For bigger A: approximate rank via `scipy.sparse.linalg.svds` on A or AᵀA (partial SVD). ([SciPy Documentation][9])
* **Block overlaps** (indexing helper, optional): `skimage.util.view_as_blocks` to get block coordinates cleanly if you need to deduce overlap ties from a block grid. ([Scikit-Image][10])

Everything is CPU-trivial at ARC scales.

---

## File & API (fixed)

**File:** `arc_cloth/model/interfaces.py`

```python
from __future__ import annotations
from typing import TypedDict, List, Dict, Any
import numpy as np
import scipy.sparse as sp

class Interfaces(TypedDict):
    A: sp.csr_matrix      # shape: [M, H*W*C]
    b: np.ndarray         # shape: [M], zeros
    __meta__: Dict[str, Any]  # receipts: M, rank, density, term counts

def build_interfaces(inv: Dict[str, Any], H: int, W: int, C: int) -> Interfaces:
    """
    Build Γ as linear equalities A·vec(X)=0 from invariants:
      - Horizontal/vertical periods (WO-04)
      - Mirror seams (WO-05)
      - Concats (WO-05)
      - Block overlaps (WO-06) [optional in v1; see below]
    Deterministic; CPU-friendly; returns CSR A and zero b.
    """
```

---

## How we encode one equality row (primitive)

To enforce (X[i,j,:]=X[i,j',:]) **for all colors (c)**, add one row for each channel:

* Let (k_1=\mathrm{ravel_multi_index}((i,j,c),(H,W,C))) and (k_2=\mathrm{ravel_multi_index}((i,j',c),(H,W,C))). ([NumPy][5])
* Add a COO triplet row with `(+1 at k1, −1 at k2)`. After assembling all rows, convert COO→CSR. COO auto-sums duplicate entries when converting, which is ideal during construction. ([SciPy Documentation][1])

You can vectorize per-row color tying by forming a small (1\times C) stencil and using **Kronecker** with a 1×(HWC) selector, but simple loops over C are fine at ARC sizes; Kron exists if needed. ([SciPy Documentation][3])

---

## Constraint sets (exact, overspecified)

All constraints below produce equality pairs ((i,j)\leftrightarrow(i',j')). For each pair, emit C channel rows as above.

### 1) Period overlaps (from WO-04)

* If `period_h = p` (stable across trains): for all rows i and columns (j=0..W-p-1), tie ((i,j) \leftrightarrow (i,j+p)).
* If `period_v = q`: for all columns j and rows (i=0..H-q-1), tie ((i,j) \leftrightarrow (i+q,j)).

### 2) Mirror seams (from WO-05)

* For each **horizontal mirror seam** index `j0` (column seam), tie for all rows i and offsets (t=0..j_{\min}-1):
  [
  (i,,j0-1-t) \leftrightarrow (i,,j0+t)
  ]
  where (j_{\min}=\min(j0,; W-j0)) so the two half-widths match.
* For each **vertical mirror seam** index `i0` (row seam), similarly tie
  [
  (i0-1-t,,j) \leftrightarrow (i0+t,,j).
  ]

### 3) Exact concats (from WO-05)

* If `"h"` in `concat_axes` (even W): tie for all rows i and columns (j=0..W/2-1):
  ((i,j) \leftrightarrow (i,,j+W/2)).
* If `"v"` (even H): tie for all columns j and rows (i=0..H/2-1):
  ((i,j) \leftrightarrow (i+H/2,,j)).

### 4) Block overlaps (from WO-06) — **optional in v1**

If you placed a (k\times k) codebook on a non-overlapping tiling, there are no intra-tiling overlaps to tie. If later you allow *sliding* reconstructions or overlapping patch votes, enforce that any pixel covered by multiple reconstructed patches must agree (emit pairwise ties for each duplicate pixel index). You can discover such duplicates by extracting patch footprints (**`view_as_blocks`** or **`view_as_windows`**) and building a small map from pixel → list of “reconstruction sources,” then tie all sources to the first. ([Scikit-Image][10])

---

## Assembly algorithm (COO triplets → CSR)

1. Pre-allocate Python lists: `rows`, `cols`, `data` and an increasing `row_id`.
2. For each equality pair ((i,j)\leftrightarrow(i',j')) and for each color `c in range(C)`:

   * `rows += [row_id, row_id]`
   * `cols += [k1, k2]` with `k1,k2 = np.ravel_multi_index(...)` (order `'C'`). ([NumPy][5])
   * `data += [1.0, -1.0]`
   * `row_id += 1`
3. Create COO: `A_coo = sp.coo_matrix((data, (rows, cols)), shape=(row_id, H*W*C))`.
   Convert: `A = A_coo.tocsr()` (fast ops, duplicates summed). ([SciPy Documentation][1])
4. `b = np.zeros(A.shape[0], dtype=float)`.

**Note:** If you prefer per-pixel single rows that sum all channels at once, you can use **Kronecker** with an identity over C; but row-per-channel is simplest and perfectly fine at ARC scale. `scipy.sparse.kron` is there if needed. ([SciPy Documentation][3])

---

## Receipts to emit (first-class)

Add to `__meta__`:

* `M`: number of equality rows (constraints).
* `density`: `A.nnz / (A.shape[0]*A.shape[1])`.
* `term_counts`: dict with counts per source (`period_h`, `period_v`, `mirror_h`, `mirror_v`, `concat_h`, `concat_v`, `block_overlap`).
* `rank`:

  * If `A.shape[0]*A.shape[1] <= small_threshold` (e.g., 1e6 entries), compute dense rank via **`numpy.linalg.matrix_rank(A.toarray())`**. ([NumPy][8])
  * Else approximate with **`scipy.sparse.linalg.svds`** on `A` or `A.T @ A` (report k used and non-zero count). ([SciPy Documentation][9])
* `shape`: `[M, H*W*C]`.
* `hash_A`: SHA-256 of `A.data`, `A.indices`, `A.indptr` (CSR triplets) to catch accidental mutations. ([NumPy][7])

---

## Debugging playbook

* **Unexpected M (too few/many)**: print `term_counts` and the first 10 row patterns; verify loop bounds for each invariant source.
* **Rank suspiciously low**: many duplicate constraints? Check for double-emits; COO→CSR sums duplicates by design. ([SciPy Documentation][1])
* **Indexing errors**: verify `ravel_multi_index` dims `(H,W,C)` and order `'C'` match your vec convention; NumPy docs show behavior. ([NumPy][5])
* **Memory**: at ARC sizes A is tiny; but if needed, build in batches (COO appends are cheap; convert once).

---

## Runner changes

* In `arc_cloth/runner/run_task.py`, add probe `"--check-gamma"`:
  load → canonicalize → infer invariants (WO-03..06) → `build_interfaces(inv,H,W,C)` → print receipts:

  * `M, rank, density, term_counts` and `shape`.
* In `scripts/run_arc.py`, `--check-gamma` writes CSV:
  `task_path,M,rank,density,shape,period_h,period_v,mirror_h,mirror_v,concat_axes`.

Reviewer rule: **100% of tasks must pass receipts** (no exceptions; Γ either empty or valid), so real bugs surface now—not at WO-09/10.

---

## Acceptance criteria

* Deterministic CSR `A` and zero vector `b`.
* Γ covers all active invariants in `inv` (mirror/concat/periods; block overlaps optional).
* Receipts: `M`, `rank` (dense or sparse SVD), `density`, `term_counts`, `hash_A`.
* Runner passes on the full ARC corpus on CPU.

---

## Minimal code sketch (only glues the cited APIs)

```python
import numpy as np
import scipy.sparse as sp
import hashlib
from typing import Dict, Any, List, Tuple

def _tie_pair(rows, cols, data, row_id, i, j, ip, jp, C, H, W):
    idx1 = np.ravel_multi_index((i, j, np.arange(C)), dims=(H, W, C), order='C')
    idx2 = np.ravel_multi_index((ip, jp, np.arange(C)), dims=(H, W, C), order='C')
    # add one row per color channel
    for k1, k2 in zip(idx1, idx2):
        rows.extend([row_id, row_id]); cols.extend([k1, k2]); data.extend([1.0, -1.0])
        row_id += 1
    return row_id

def build_interfaces(inv: Dict[str, Any], H: int, W: int, C: int) -> Dict[str, Any]:
    rows: List[int] = []; cols: List[int] = []; data: List[float] = []
    row_id = 0; term_counts = dict(period_h=0, period_v=0, mirror_h=0, mirror_v=0,
                                   concat_h=0, concat_v=0, block_overlap=0)

    # periods
    p = inv.get("period_h"); q = inv.get("period_v")
    if p is not None and p > 0:
        for i in range(H):
            for j in range(W - p):
                row_id = _tie_pair(rows, cols, data, row_id, i, j, i, j + p, C, H, W)
                term_counts["period_h"] += C
    if q is not None and q > 0:
        for j in range(W):
            for i in range(H - q):
                row_id = _tie_pair(rows, cols, data, row_id, i, j, i + q, j, C, H, W)
                term_counts["period_v"] += C

    # mirror seams (lists may be empty)
    for j0 in inv.get("mirror_h_seams", []):
        w = min(j0, W - j0)
        for i in range(H):
            for t in range(w):
                row_id = _tie_pair(rows, cols, data, row_id, i, j0 - 1 - t, i, j0 + t, C, H, W)
                term_counts["mirror_h"] += C
    for i0 in inv.get("mirror_v_seams", []):
        h = min(i0, H - i0)
        for j in range(W):
            for t in range(h):
                row_id = _tie_pair(rows, cols, data, row_id, i0 - 1 - t, j, i0 + t, j, C, H, W)
                term_counts["mirror_v"] += C

    # concats
    if "h" in inv.get("concat_axes", []) and W % 2 == 0:
        k = W // 2
        for i in range(H):
            for j in range(k):
                row_id = _tie_pair(rows, cols, data, row_id, i, j, i, j + k, C, H, W)
                term_counts["concat_h"] += C
    if "v" in inv.get("concat_axes", []) and H % 2 == 0:
        k = H // 2
        for j in range(W):
            for i in range(k):
                row_id = _tie_pair(rows, cols, data, row_id, i, j, i + k, j, C, H, W)
                term_counts["concat_v"] += C

    # assemble CSR
    A = sp.coo_matrix((data, (rows, cols)), shape=(row_id, H * W * C)).tocsr()  # COO→CSR sums duplicates :contentReference[oaicite:22]{index=22}
    b = np.zeros(A.shape[0], dtype=float)

    # receipts
    M = int(A.shape[0]); density = float(A.nnz) / (A.shape[0] * A.shape[1]) if A.shape[0] and A.shape[1] else 0.0
    rank = None
    try:
        if A.shape[0] * A.shape[1] <= 1_000_000:
            import numpy.linalg as npl
            rank = int(npl.matrix_rank(A.toarray()))  # dense SVD rank :contentReference[oaicite:23]{index=23}
        else:
            from scipy.sparse.linalg import svds
            # crude lower bound via top-k singulars
            k = min(32, min(A.shape) - 1)
            s = svds(A, k=k, return_singular_vectors=False)  # partial SVD :contentReference[oaicite:24]{index=24}
            rank = int(np.count_nonzero(s > 1e-10))
    except Exception:
        rank = None

    hash_A = hashlib.sha256(
        b"".join([A.data.tobytes(), A.indices.tobytes(), A.indptr.tobytes()])
    ).hexdigest()

    return {"A": A, "b": b,
            "__meta__": {"M": M, "rank": rank, "density": density,
                         "term_counts": term_counts, "shape": [int(A.shape[0]), int(A.shape[1])],
                         "hash_A": hash_A,
                         "method": {"coo": "scipy.sparse.coo_matrix", "csr": "scipy.sparse.csr_matrix",
                                    "kron": "scipy.sparse.kron", "ravel_multi_index": "numpy.ravel_multi_index"}}}
```

---

## Reviewer protocol (corpus-wide)

1. Ensure Π-normalized inputs and invariants exist (WO-02..06 receipts green).
2. Run:

```
python scripts/run_arc.py \
  --root /path/to/arc-json \
  --mode canon \
  --check-gamma \
  --limit 999999
```

3. Verify for **100% of tasks**:

* No exceptions.
* `shape[1] == H*W*C`, `b == 0`.
* `M` and `term_counts` are sensible (zero when invariant absent).
* For spot checks, feed `(A,b)` with CVXPY path; equality residuals ≈ 0 after solve (per `04-receipts-checklist.md`).

---

[1]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html?utm_source=chatgpt.com "coo_matrix — SciPy v1.16.2 Manual"
[2]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html?utm_source=chatgpt.com "csr_matrix — SciPy v1.16.2 Manual"
[3]: https://docs.scipy.org/doc/scipy-1.15.2/reference/generated/scipy.sparse.kron.html?utm_source=chatgpt.com "kron — SciPy v1.15.2 Manual"
[4]: https://docs.scipy.org/doc/scipy-1.7.0/reference/reference/sparse.html?utm_source=chatgpt.com "Sparse matrices (scipy.sparse) — SciPy v1.7.0 Manual"
[5]: https://numpy.org/doc/2.1/reference/generated/numpy.ravel_multi_index.html?utm_source=chatgpt.com "numpy.ravel_multi_index — NumPy v2.1 Manual"
[6]: https://numpy.org/devdocs/reference/generated/numpy.ravel.html?utm_source=chatgpt.com "numpy.ravel — NumPy v2.4.dev0 Manual"
[7]: https://numpy.org/doc/stable/user/basics.indexing.html?utm_source=chatgpt.com "Indexing on ndarrays — NumPy v2.3 Manual"
[8]: https://numpy.org/doc/2.2/reference/generated/numpy.linalg.matrix_rank.html?utm_source=chatgpt.com "numpy.linalg.matrix_rank — NumPy v2.2 Manual"
[9]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html?utm_source=chatgpt.com "svds — SciPy v1.16.2 Manual"
[10]: https://scikit-image.org/docs/0.25.x/auto_examples/numpy_operations/plot_view_as_blocks.html?utm_source=chatgpt.com "Block views on images/arrays"
