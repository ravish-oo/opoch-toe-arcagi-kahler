# WO-03 — Invariants: color counts (Π-stable, FREE-invariant)

## Purpose

Compute **per-color totals from train outputs** in a way that is:

* **Π-stable** (after WO-02 canonicalizer), and
* **FREE-invariant** under shape-aware dihedral actions (D₄ for squares, D₂ for rectangles).

ARC grids are **rectangular matrices** of **ints 0–9**, sizes **1×1…30×30**, bundled as JSON `{"train":[...], "test":[...]}`. We use **train outputs only**. ([GitHub][1])

## Anchors to read (before coding)

* `docs/anchors/00-vision-universe.md` — A0 Π, FREE moves.
* `docs/anchors/01-arc-on-the-cloth.md` — ARC↔cloth map; FREE=D4/D2; invariants feed D.
* `docs/anchors/03-invariants-catalog-v1.md` §1 — Color histogram term.
* `docs/anchors/04-receipts-checklist.md` — FREE invariance receipts.

## Reused libraries (no custom algorithms)

* **NumPy** for counting and exact array isometries:

  * `np.bincount` to count colors on flattened integer grids. ([numpy.org][2])
  * `np.rot90` for 90/180/270° rotations. ([numpy.org][3])
  * `np.flip` (and `axis=0/1`) for vertical/horizontal reflections. ([numpy.org][4])
* **Hypothesis** (property-based tests) to assert D4/D2 invariance generically. ([Hypothesis][5])

*(Optional later: JAX has drop-in `jnp.bincount/rot90/flip` if you ever want GPU, but we stay CPU for v1.)* ([docs.jax.dev][6])

---

## File & API (fixed)

**File:** `arc_cloth/model/invariants.py`

```python
from __future__ import annotations
from typing import TypedDict, List, Dict, Any
import numpy as np

class ColorCounts(TypedDict):
    counts: List[int]         # length C, totals per palette index 0..C-1
    palette_size: int         # C
    source: str               # "train_outputs"
    __meta__: Dict[str, Any]  # receipts: invariance checks, shapes, hashes, etc.

def infer_color_counts(train: List[Dict[str, List[List[int]]]]) -> ColorCounts:
    """
    Compute per-color totals from Π-normalized train outputs.

    Requirements:
      - Deterministic.
      - Invariant under FREE isometries (shape-aware D4 for squares, D2 for rectangles).
      - Uses train outputs only, never test inputs.
    Raises ValueError with actionable context if assumptions are violated.
    """
```

**Assumptions:** WO-02 has already produced Π-normalized grids with **pose canonicalized** (D₄ squares / D₂ rectangles) and **palette remapped** to contiguous `[0..C−1]` in **ascending numeric order**. (ARC colors are 0–9.) ([GitHub][1])

---

## Exact mechanics (no invention)

1. **Collect outputs only**

```python
outs = [np.asarray(p["output"], dtype=np.int16) for p in train]
if not outs: raise ValueError("No train outputs")
```

2. **Guardrails** (cheap, belt-and-suspenders):

* values in `[0..9]` (ARC spec) and `ndim==2`. ([GitHub][1])

3. **Palette size**
   Because WO-02 remapped to contiguous indices, `C = max_val + 1`.

4. **Counts via NumPy**
   For each grid `G`, use **`np.bincount(G.ravel(), minlength=C)`**, then sum over outputs:

```python
counts = sum(np.bincount(G.ravel(), minlength=C) for G in outs)
```

`np.bincount` is the canonical way to count nonnegative integer occurrences. ([numpy.org][2])

5. **FREE invariance receipt** (shape-aware):

* If `H==W` (square): verify equality of bincounts after **all 8 D₄** transforms (`R0,R90,R180,R270,Fh,Fv, Fd1, Fd2` derived with `rot90`/`flip`). ([numpy.org][3])
* If `H≠W` (rectangle): verify over the **D₂** subset that preserves shape (`R0,R180,Fh,Fv`).
  Record per-grid `{shape, group, base_counts, free_ok}`.

6. **Receipts** (attach in `__meta__`):

* `free_invariance_ok: bool` (all outputs pass)
* `per_grid_counts: [...]` with `{shape, group, free_ok}`
* `palette_size: C`, `sum_pixels`, `n_outputs`, `n_square`, `n_rect`
* `hash_counts: sha256(counts)`

---

## What **not** to do

* No hand-rolled counters or loops; always use `np.bincount` (handles zeros/missing colors and outputs fixed length via `minlength`) ([numpy.org][2])
* No ad-hoc symmetry code; only `np.rot90` / `np.flip` exactly as documented. ([numpy.org][3])
* No dynamic palette inference beyond `max()+1`; WO-02 guarantees contiguity.

---

## Runner changes (so reviewer can test on real ARC)

* Extend `run_task.py` to add a probe step when `--check-invariants color_counts`:

  * load → canonicalize → `infer_color_counts(train)` → print receipts:
    `palette_size, sum_pixels, free_invariance_ok, n_square, n_rect, hash_counts`.
* Extend `scripts/run_arc.py`:

  * `--check-invariants color_counts` writes a CSV with
    `task_path,palette_size,sum_pixels,free_invariance_ok,n_outputs,n_square,n_rect,hash_counts`.

**Why this works at scale:** ARC is a directory of JSON tasks with 0–9 ints and small sizes, so this is trivial on CPU. ([GitHub][1])

---

## Reviewer protocol (corpus-wide)

1. Read anchors `00` (§1–3) and `01` (§1–2, §6).
2. Run:

```
python scripts/run_arc.py \
  --root /path/to/arc-json \
  --mode canon \
  --check-invariants color_counts \
  --limit 999999
```

3. Expect per task:

* `free_invariance_ok=True`
* `palette_size` equals number of unique colors across train outputs
* `sum_pixels == sum(H*W over train outputs)`

**If anything fails**:

* If a **rectangular** grid was tested against D₄ (includes 90°), that’s an **implementation bug**—rectangles must use D₂ only.
* If counts mismatch only on a single grid, print its `bincount` vectors before/after each transform and verify you didn’t accidentally include the **input** grid or the **test** grid.

---

## Acceptance criteria

* **FREE invariance:** `free_invariance_ok=True` for **all** tasks across the corpus.
* **Determinism:** repeated runs produce identical `counts` and `hash_counts`.
* **Π precondition:** if WO-02 receipts aren’t present or show not-canonical, raise.
* **CPU-friendly:** all operations are O(#pixels); no timeouts on full ARC.

---

## Minimal code sketch (so Claude calls the right APIs)

```python
import numpy as np, hashlib
from typing import List, Dict, Any

def _bincount(G: np.ndarray, C: int) -> np.ndarray:
    return np.bincount(G.ravel(), minlength=C)

def _shape_aware_transforms(H: int, W: int):
    fh = lambda a: np.flip(a, 0)
    fv = lambda a: np.flip(a, 1)
    if H == W:
        return [
            lambda a: a,
            lambda a: np.rot90(a,1),
            lambda a: np.rot90(a,2),
            lambda a: np.rot90(a,3),
            fh, fv,
            lambda a: np.flip(np.rot90(a,1), 0),
            lambda a: np.flip(np.rot90(a,1), 1),
        ], "D4"
    else:
        return [lambda a: a, lambda a: np.rot90(a,2), fh, fv], "D2"

def infer_color_counts(train: List[Dict[str, List[List[int]]]]) -> Dict[str, Any]:
    outs = [np.asarray(p["output"], dtype=np.int16) for p in train]
    if not outs: raise ValueError("No train outputs")
    vmin = min(int(o.min()) for o in outs)
    vmax = max(int(o.max()) for o in outs)
    if vmin < 0 or vmax > 9:
        raise ValueError(f"Values out of [0..9]: min={vmin}, max={vmax}")  # ARC spec
    C = vmax + 1

    counts = np.zeros(C, dtype=np.int64)
    per, n_sq, n_rect = [], 0, 0
    for o in outs:
        H, W = o.shape
        tfuns, tag = _shape_aware_transforms(H, W)
        n_sq += (tag == "D4"); n_rect += (tag == "D2")
        base = _bincount(o, C)
        free_ok = all(np.array_equal(base, _bincount(T(o), C)) for T in tfuns)
        per.append({"shape":[H,W], "group": tag, "free_ok": free_ok, "counts": base.tolist()})
        counts += base

    meta = {
        "free_invariance_ok": all(p["free_ok"] for p in per),
        "per_grid_counts": per,
        "palette_size": int(C),
        "sum_pixels": int(sum(int(o.size) for o in outs)),
        "n_outputs": len(outs), "n_square": int(n_sq), "n_rect": int(n_rect),
        "hash_counts": hashlib.sha256(counts.tobytes()).hexdigest(),
    }
    return {"counts": counts.tolist(), "palette_size": int(C), "source": "train_outputs", "__meta__": meta}
```

---

[1]: https://github.com/fchollet/ARC-AGI?utm_source=chatgpt.com "fchollet/ARC-AGI: The Abstraction and Reasoning Corpus"
[2]: https://numpy.org/doc/2.1/reference/generated/numpy.bincount.html?utm_source=chatgpt.com "numpy.bincount — NumPy v2.1 Manual"
[3]: https://numpy.org/doc/2.2/reference/generated/numpy.rot90.html?utm_source=chatgpt.com "numpy.rot90 — NumPy v2.2 Manual"
[4]: https://numpy.org/doc/2.1/reference/generated/numpy.flip.html?utm_source=chatgpt.com "numpy.flip — NumPy v2.1 Manual"
[5]: https://hypothesis.readthedocs.io/?utm_source=chatgpt.com "Hypothesis 6.142.5 documentation"
[6]: https://docs.jax.dev/en/latest/_autosummary/jax.numpy.bincount.html?utm_source=chatgpt.com "jax.numpy.bincount"
