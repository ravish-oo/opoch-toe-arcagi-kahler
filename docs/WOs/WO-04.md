# WO-04 — Invariants: periods (H/V) via autocorrelation

## Purpose

Detect **fundamental horizontal and vertical periods** on ARC **train outputs**, in a way that is Π-stable (after WO-02), FREE-invariant (rotation swaps H/V), and deterministic across the corpus. ARC grids are **rectangular** matrices of **ints 0–9**, sizes **1×1…30×30**, provided as JSON with `train` pairs and a `test` input. ([Kaggle][1])

## Anchors to read (before coding)

* `docs/anchors/00-vision-universe.md` — Π/FREE, “negation first”.
* `docs/anchors/01-arc-on-the-cloth.md` — ARC↔cloth mapping; invariants feed (D).
* `docs/anchors/03-invariants-catalog-v1.md` §2 — Tiling/periodicity term.
* `docs/anchors/04-receipts-checklist.md` — FREE-invariance receipts; “all tasks pass receipts” requirement.

---

## Reused libraries (no algorithm invention)

* **SciPy signal** for autocorrelation:

  * `scipy.signal.correlate` (1-D) to compute row/column autocorr. ([SciPy Documentation][2])
  * (Optionally) `scipy.signal.correlation_lags` to map indices to lags. ([SciPy Documentation][3])
  * For 2-D motifs (future), `scipy.signal.correlate2d` exists; not required in this WO. ([SciPy Documentation][4])
* **NumPy** for exact FREE isometries and array ops:

  * `np.rot90`, `np.flip*` for D4/D2 checks. ([NumPy][5])
* **Hypothesis** for property-based invariance tests (rotation swaps H/V). ([Hypothesis][6])

CPU only; all arrays are ≤30×30 so SciPy/NumPy are instantaneous.

---

## File & API (fixed)

**File:** `arc_cloth/model/invariants.py`

```python
from __future__ import annotations
from typing import TypedDict, List, Dict, Any, Optional

class Periods(TypedDict):
    period_h: Optional[int]   # None or integer p, 1 <= p < W
    period_v: Optional[int]   # None or integer q, 1 <= q < H
    __meta__: Dict[str, Any]  # receipts: per-grid votes, confidences, invariance checks

def infer_periods(train: List[Dict[str, List[List[int]]]]) -> Periods:
    """
    Detect fundamental horizontal (row-wise) and vertical (column-wise) periods
    from Π-normalized train outputs.

    Requirements:
      - Deterministic.
      - 'Stable across all train pairs' -> return a single p (or q) if all outputs agree; else None.
      - FREE invariance: rotating outputs by 90° swaps detected H/V periods.
    """
```

**Assumptions:** WO-02 already applied **shape-aware** canonicalization (D₄ for squares; D₂ for rectangles) and **ascending-numeric** palette remap. ARC grids remain rectangular 2-D int arrays 0–9. ([Kaggle][1])

---

## Exact method (library-backed, reproducible)

We detect **per-grid** candidate periods then aggregate **across all train outputs**.

### 1) Per-row horizontal period candidate (p)

For each output grid (G) with width (W):

* For each row vector (r \in {0,\dots,H-1}), compute **autocorrelation** (a = \text{correlate}(x_r, x_r, \text{mode}='full')). The zero-lag peak is at center. ([SciPy Documentation][2])
* Consider **positive lags** (1\le\ell \le W-1). Define the **score** (s(\ell)=a[\text{center}+\ell]).
* Let (p_r) be the **smallest** (\ell>0) achieving the **maximal** (s(\ell)) over (1..W-1). (Earliest strongest repetition.)
* Optional normalization (stable at small sizes): scale (s(\ell)) by row energy (||x_r||_2^2) to compare rows; SciPy returns raw cross-corr which is fine because rows are identical scales (integers 0–9). We keep it simple for v1.

Aggregate per-row votes (multiset of (p_r)) and choose the **mode** as the grid’s (p^{(G)}). If ties, pick the **smallest** (earliest repetition).

> Implementation notes:
>
> * `scipy.signal.correlate(row, row, mode='full')` then examine the right half. Use `np.argmax` on that slice for the peak, and take the **first** index among equals. ([SciPy Documentation][2])

### 2) Per-column vertical period candidate (q)

Apply the same logic on **columns** (or compute on `G.T`). Range (1..H-1). Again choose grid (q^{(G)}) by mode over column votes.

### 3) Across-outputs stability rule

Collect ({p^{(G)}}) for **all train outputs**. If **all equal** (same (p)), return that as `period_h`; else return `None`. Same for `period_v`.

### 4) Confidence score (for receipts)

Report **agreement fractions**:

* `conf_h = (# of outputs equal to chosen p) / (# outputs)` (0 if None)
* `conf_v = (# of outputs equal to chosen q) / (# outputs)`

These are receipts only; v1 **requires 100% agreement** to accept a period. Anything less returns `None`.

### 5) FREE-invariance receipt

For one representative output grid (G):

* Let `(p_h, p_v)` be the detected periods on (G).
* On (G_{90} = np.rot90(G, 1)`, detect periods again; require `(p_v, p_h)` within the same detection logic (swap as expected). Use shape-aware FREE set for checks (D₄ for square, D₂ for rectangle; for D₂ we only verify 180° and flips, which **preserve** H/V). ([NumPy][5])

---

## Receipts to emit (first-class)

Return in `__meta__`:

* `per_grid: List[{"shape":[H,W],"p_h": Optional[int],"p_v": Optional[int],"votes_h": List[int],"votes_v": List[int]}]`
* `stable_h: bool`, `stable_v: bool`, `conf_h: float`, `conf_v: float`
* `free_invariance_ok: bool` — rotation swaps H/V on a sample grid (or on each grid if you wish)
* `method: {"autocorr": {"backend":"scipy.signal.correlate","mode":"full"}}`
* `hash_periods: str` — SHA-256 of `(period_h, period_v, conf_h, conf_v)` for reproducibility

The reviewer will assert **all tasks** pass these receipts (either a period with 100% agreement or `None` with proper flags) across the corpus.

---

## Debugging playbook (implementer)

* **Different periods per train output:** that’s legitimate → return `None`. Confirm `conf_* < 1.0` and `stable_* = False`.
* **Row/col mismatch after rotation:** ensure you used **shape-aware FREE** (rectangles use D₂; 90° rotates swap H/W but change shape). Rotate a **square** grid to test D₄ swap; use 180°/flips on rectangles to confirm invariance without H/V swap. ([NumPy][5])
* **Flat autocorr (no peaks):** the mode will be at lag=1; if outputs disagree, stability will force `None`. That’s correct.

---

## Runner changes (so reviewer can test on real ARC)

* **`run_task.py`**: add `"--check-invariants periods"` probe.

  * load → canonicalize (WO-02) → `infer_periods(train)` → print receipts: `period_h, period_v, conf_h, conf_v, free_invariance_ok`.
* **`scripts/run_arc.py`**: when `--check-invariants periods`, write CSV:

  * `task_path, period_h, period_v, conf_h, conf_v, stable_h, stable_v, free_invariance_ok`.

The ARC corpus (JSON of 0–9 ints, 1×1..30×30 grids) makes this CPU-trivial. ([Kaggle][1])

---

## Reviewer protocol (corpus-wide)

1. Read `00` (§1–3), `01` (§1–2, §6), `03` (§2), `04`.
2. Run:

```
python scripts/run_arc.py \
  --root /path/to/arc-json \
  --mode canon \
  --check-invariants periods \
  --limit 999999
```

3. Verify per task:

   * `stable_h=True` ⇒ all outputs produced the **same** `period_h`; else `period_h=None`.
   * `stable_v=True` ⇒ all outputs produced the **same** `period_v`; else `period_v=None`.
   * `free_invariance_ok=True`.
4. **Checklist item (new):** confirm “**100% of tasks pass receipts**” (i.e., no exception; every task returns either a stable period or clean `None` with confidences) to avoid surprises later.

---

## Minimal code sketch (so Claude calls the right APIs)

```python
import numpy as np
from scipy.signal import correlate  # 1-D autocorr backend
import hashlib
from typing import List, Dict, Any, Optional

def _row_periods(G: np.ndarray) -> List[int]:
    H, W = G.shape
    per = []
    for r in range(H):
        x = G[r, :].astype(np.int16)
        a = correlate(x, x, mode='full')                  # length 2W-1
        mid = W - 1
        pos = a[mid+1:]                                   # lags 1..W-1
        best = np.argmax(pos) + 1                         # earliest max lag
        per.append(int(best))
    return per

def _col_periods(G: np.ndarray) -> List[int]:
    return _row_periods(G.T)

def _stable_mode(votes: List[int]) -> Optional[int]:
    # earliest period if unanimous; else None
    if not votes: return None
    first = votes[0]
    if all(p == first for p in votes):
        # unanimity across rows (or across outputs later)
        return int(first)
    return None

def infer_periods(train: List[Dict[str, List[List[int]]]]) -> Dict[str, Any]:
    outs = [np.asarray(p["output"], dtype=np.int16) for p in train]
    if not outs: raise ValueError("No train outputs")

    # per-grid candidates
    per_grid = []
    for G in outs:
        votes_h = _row_periods(G) if G.shape[1] > 1 else []
        votes_v = _col_periods(G) if G.shape[0] > 1 else []
        p_h = _stable_mode(votes_h)  # unanimity across rows
        p_v = _stable_mode(votes_v)  # unanimity across cols
        per_grid.append({"shape":[int(G.shape[0]), int(G.shape[1])],
                         "p_h": p_h, "p_v": p_v,
                         "votes_h": votes_h, "votes_v": votes_v})

    # across-outputs stability
    # collect non-None values; require they are equal across outputs
    def across(vals):
        vals = [v for v in vals if v is not None]
        if len(vals) == 0: return None, False, 0.0
        unanimous = all(v == vals[0] for v in vals)
        conf = (sum(v == vals[0] for v in vals) / len(outs)) if vals else 0.0
        return (int(vals[0]) if unanimous else None), unanimous, float(conf)

    period_h, stable_h, conf_h = across([g["p_h"] for g in per_grid])
    period_v, stable_v, conf_v = across([g["p_v"] for g in per_grid])

    # FREE invariance: quick check on a square grid if available else use 180° for rectangle
    free_ok = True
    for G in outs:
        H, W = G.shape
        if H == W:
            Gh = np.rot90(G, 1)                  # 90° swap H/V
            # detect again on Gh (single-grid)
            gh_h = _row_periods(Gh); gh_v = _col_periods(Gh)
            p_h_G  = _stable_mode(_row_periods(G))
            p_v_G  = _stable_mode(_col_periods(G))
            p_h_Gh = _stable_mode(gh_h)
            p_v_Gh = _stable_mode(gh_v)
            if p_h_G is not None and p_v_G is not None:
                free_ok = free_ok and (p_h_G == p_v_Gh and p_v_G == p_h_Gh)
            # one square grid check is enough
            break
        else:
            # rectangle: verify invariance under 180° (no swap expected)
            G2 = np.rot90(G, 2)
            if _stable_mode(_row_periods(G)) != _stable_mode(_row_periods(G2)):
                free_ok = False
                break
            if _stable_mode(_col_periods(G)) != _stable_mode(_col_periods(G2)):
                free_ok = False
                break

    meta = {
        "per_grid": per_grid,
        "stable_h": bool(stable_h), "stable_v": bool(stable_v),
        "conf_h": float(conf_h), "conf_v": float(conf_v),
        "free_invariance_ok": bool(free_ok),
        "method": {"autocorr": {"backend":"scipy.signal.correlate","mode":"full"}},
        "hash_periods": hashlib.sha256(
            np.array([period_h or -1, period_v or -1,
                      int(1000*conf_h), int(1000*conf_v)], dtype=np.int64).tobytes()
        ).hexdigest(),
    }
    return {"period_h": period_h, "period_v": period_v, "__meta__": meta}
```

**Why `scipy.signal.correlate`:** It’s the canonical SciPy routine for N-D cross-/auto-correlation, well-documented and stable; `mode='full'` centers the zero-lag peak, and we scan positive lags only. ([SciPy Documentation][2])

---

## Acceptance criteria

* **Receipts pass on 100% of tasks**: every task returns either stable `(period_h, period_v)` with `stable_* = True` or clean `None` with consistent confidences; **no exceptions** across the corpus.
* **FREE invariance**: `free_invariance_ok=True`.
* **Determinism**: repeated runs yield identical `hash_periods`.
* **Π-precondition**: if input is not Π-normalized (caught by WO-02 receipts), raise a clear error.
* **CPU-friendly**: runs over full ARC on CPU without timeouts (O(HW·(H+W)) per grid; grids are ≤30×30).
* **D4 expectation**: rotation swaps H/V periods for **squares**; for rectangles we check invariance under 180° (D₂), per WO-02 shape-aware policy and NumPy transforms. ([NumPy][5])

---

[1]: https://www.kaggle.com/competitions/arc-prize-2024/data?select=sample_submission.json&utm_source=chatgpt.com "ARC Prize 2024 | Kaggle"
[2]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.correlate.html?utm_source=chatgpt.com "correlate — SciPy v1.16.2 Manual"
[3]: https://docs.scipy.org/doc/scipy/reference/signal.html?utm_source=chatgpt.com "Signal processing (scipy.signal) — SciPy v1.16.2 Manual"
[4]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.correlate2d.html?utm_source=chatgpt.com "correlate2d — SciPy v1.16.2 Manual"
[5]: https://numpy.org/doc/2.2/reference/generated/numpy.rot90.html?utm_source=chatgpt.com "numpy.rot90 — NumPy v2.2 Manual"
[6]: https://hypothesis.readthedocs.io/?utm_source=chatgpt.com "Hypothesis 6.142.5 documentation"
